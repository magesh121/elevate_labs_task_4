Breast Cancer Classification with Logistic Regression
AI & ML Internship - Task 4
ğŸ¯ Project Objective
Develop a binary classification model using logistic regression to accurately predict breast cancer diagnosis (Malignant vs Benign) based on cell nuclei characteristics from the Breast Cancer Wisconsin Dataset.
ğŸ“Š Dataset Information

Source: Breast Cancer Wisconsin Dataset (Scikit-learn)
Features: 30 numerical features computed from digitized images
Target: Binary classification (0: Malignant, 1: Benign)
Samples: 569 total samples
Class Distribution:

Malignant: 212 samples (37.3%)
Benign: 357 samples (62.7%)



ğŸ›  Tools & Libraries Used

Python 3.x
Scikit-learn - Machine learning algorithms
Pandas - Data manipulation
NumPy - Numerical computations
Matplotlib & Seaborn - Data visualization
Warnings - Error handling

ğŸ“ Project Structure
logistic-regression-classification/
â”‚
â”œâ”€â”€ logistic_regression_classifier.py    # Main implementation
â”œâ”€â”€ README.md                            # Project documentation                     
â””â”€â”€ visualizations/                      # Generated charts and graphs
    â”œâ”€â”€ data_exploration.png
    â”œâ”€â”€ feature_scaling.png
    â”œâ”€â”€ sigmoid_function.png
    â”œâ”€â”€ confusion_matrix.png
    â”œâ”€â”€ performance_analysis.png
    â””â”€â”€ feature_importance.png
ğŸš€ How to Run

Clone the repository:
bashgit clone [your-repo-url]
cd logistic-regression-classification

Run the main script:
bashpython logistic_regression_classifier.py


ğŸ“ˆ Key Results
Model Performance Metrics
MetricValueAccuracy96.5%Precision95.8%Recall97.9%F1-Score96.8%ROC-AUC99.2%
Confusion Matrix Results
              Predicted
              Mal   Ben
Actual  Mal   40     3
        Ben    1    70
Performance Breakdown:

True Negatives (TN): 40 - Correctly identified malignant cases
False Positives (FP): 3 - Incorrectly predicted as benign
False Negatives (FN): 1 - Missed malignant case (critical error)
True Positives (TP): 70 - Correctly identified benign cases

ğŸ” Key Insights & Analysis
1. Data Characteristics

Dataset Balance: 37.3% Malignant, 62.7% Benign (moderately imbalanced)
Feature Types: 30 numerical features across mean, worst, and standard error measurements
Strong Predictors: Size-related features (radius, perimeter, area) and texture features show high discriminative power

2. Model Performance

Excellent Classification: 96.5% accuracy with high precision and recall
Low False Negative Rate: Only 1 missed malignant case (critical for medical diagnosis)
Strong Generalization: ROC-AUC of 0.992 indicates excellent discriminative ability

3. Feature Importance Insights
Top 5 Most Influential Features:

Worst Concave Points - Strongest predictor of malignancy
Worst Perimeter - Tumor boundary characteristics
Mean Concave Points - Cell shape irregularities
Worst Radius - Tumor size indicator
Mean Concavity - Surface texture features

Feature Categories Analysis:

Worst Features: Highest predictive power (extreme values)
Mean Features: Consistent baseline indicators
Standard Error Features: Lower but still significant contribution

4. Sigmoid Function Analysis

Successfully maps linear combinations to probabilities [0,1]
Smooth decision boundary at default threshold (0.5)
Clear separation between malignant and benign probability distributions

5. Threshold Optimization

Default Threshold (0.5): Optimal for balanced performance
Precision-Recall Trade-off: Well-balanced with minimal false negatives
Clinical Consideration: Low false negative rate prioritized for safety

ğŸ“ Learning Outcomes
Technical Skills Gained:

âœ… Binary classification implementation
âœ… Feature standardization techniques
âœ… Model evaluation metrics understanding
âœ… ROC curve and AUC interpretation
âœ… Threshold tuning strategies
âœ… Confusion matrix analysis

Key Concepts Mastered:

Logistic vs Linear Regression differences
Sigmoid function mathematics
Precision vs Recall trade-offs
Class imbalance handling
Multi-class extension possibilities

Feature Engineering: Create polynomial features or interactions
Regularization: Implement L1/L2 regularization for feature selection
Cross-Validation: Use k-fold CV for more robust evaluation
Ensemble Methods: Compare with Random Forest, SVM
Hyperparameter Tuning: Grid search for optimal parameters

ğŸ“š References

Scikit-learn Documentation
Breast Cancer Wisconsin Dataset
Logistic Regression Theory
